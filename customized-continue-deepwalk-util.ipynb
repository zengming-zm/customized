{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import random\n",
    "import math\n",
    "import h5py\n",
    "from multiprocessing import cpu_count\n",
    "import scipy.io as sio\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from collections import defaultdict\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from six import iteritems\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "from numpy import genfromtxt\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "\n",
    "from collections import defaultdict as dd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.init_ops import glorot_uniform_initializer, RandomUniform, RandomNormal\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import Vocab\n",
    "\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluatoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse2graph(x):\n",
    "    G = defaultdict(lambda: set())\n",
    "    cx = x.tocoo()\n",
    "    for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "        G[i].add(j)\n",
    "    return {str(k): [str(x) for x in v] for k,v in iteritems(G)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopKRanker(OneVsRestClassifier):\n",
    "    def predict(self, X, top_k_list):\n",
    "        assert X.shape[0] == len(top_k_list)\n",
    "        probs = np.asarray(super(TopKRanker, self).predict_proba(X))\n",
    "        all_labels = []\n",
    "        for i, k in enumerate(top_k_list):\n",
    "            probs_ = probs[i, :]\n",
    "            labels = self.classes_[probs_.argsort()[-k:]].tolist()\n",
    "            all_labels.append(labels)\n",
    "        return all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, mlb, X_train, y_train, X_test, y_test, mode):\n",
    "\n",
    "    all_results_trn = defaultdict(list)\n",
    "    all_results_tst = defaultdict(list)\n",
    "    \n",
    "    # find out how many labels should be predicted\n",
    "    top_k_list = [len(l) for l in y_train]\n",
    "    trn_preds = clf.predict(X_train, top_k_list)\n",
    "    top_k_list = [len(l) for l in y_test]\n",
    "    tst_preds = clf.predict(X_test, top_k_list)\n",
    "\n",
    "    results_trn = {}\n",
    "    results_tst = {}\n",
    "    averages = [\"micro\", \"macro\"]\n",
    "    for average in averages:\n",
    "        results_trn[average] = f1_score(mlb.fit_transform(y_train), mlb.fit_transform(trn_preds), average=average)\n",
    "        results_tst[average] = f1_score(mlb.fit_transform(y_test), mlb.fit_transform(tst_preds), average=average)\n",
    "    all_results_trn[mode].append(results_trn)\n",
    "    all_results_tst[mode].append(results_tst)\n",
    "    \n",
    "    return all_results_trn, all_results_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_multi_label_classifier(mlb, X_train, y_train, X_test, y_test, mode):\n",
    "    \n",
    "    all_results_trn = defaultdict(list)\n",
    "    all_results_tst = defaultdict(list)\n",
    "    \n",
    "    g = tf.Graph()\n",
    "    with g.as_default(), tf.device('/cpu:0'):\n",
    "        features = tf.placeholder(tf.float32, shape=[None, 128])\n",
    "        labels = tf.placeholder(tf.float32, shape=[None, 39])\n",
    "        w = tf.Variable(tf.truncated_normal([128, 39]))\n",
    "        b = tf.Variable(tf.zeros([39]))\n",
    "    \n",
    "#         logit_y = tf.layers.dense(inputs = features, units = labels.shape[1],\n",
    "#                                   activation=tf.nn.sigmoid, kernel_initializer=glorot_uniform_initializer())\n",
    "\n",
    "        logit_y = tf.matmul(features, w) + b\n",
    "    \n",
    "        clf_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logit_y, labels = labels))\n",
    "    \n",
    "        clf_optimizer = tf.train.AdamOptimizer(learning_rate=0.25).minimize(clf_loss)\n",
    "        \n",
    "        predictions = tf.nn.sigmoid(logit_y)\n",
    "    \n",
    "    with tf.Session(graph=g) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        avg_l = 0\n",
    "        for i in range(2000000):\n",
    "            feed_dict = {features: X_train,\n",
    "                         labels: y_train}\n",
    "            \n",
    "            _, l, res_predictions = session.run([clf_optimizer, clf_loss, predictions], feed_dict = feed_dict)\n",
    "            avg_l += l\n",
    "            if (i % 2000 == 0):\n",
    "                print('loss: %f' %(avg_l / 2000.0))\n",
    "                avg_l = 0\n",
    "        \n",
    "                res_y_pred = tf.round(predictions)\n",
    "                res_y_true = tf.round(labels)\n",
    "\n",
    "                tst_y_pred = res_y_pred.eval({features: X_test, labels: y_test})\n",
    "                tst_y_true = res_y_true.eval({features: X_test, labels: y_test})\n",
    "                trn_y_pred = res_y_pred.eval({features: X_train, labels: y_train})\n",
    "                trn_y_true = res_y_true.eval({features: X_train, labels: y_train})\n",
    "\n",
    "                tst_logit_y = logit_y.eval({features: X_test, labels: y_test})\n",
    "                \n",
    "#                 print('tst_feature:')\n",
    "#                 print(X_test[0])\n",
    "                \n",
    "#                 sys.exit(0)\n",
    "\n",
    "                results_trn = {}\n",
    "                results_tst = {}\n",
    "                averages = [\"micro\", \"macro\"]\n",
    "                for average in averages:\n",
    "                    results_trn[average] = f1_score(trn_y_true, trn_y_pred, average=average)\n",
    "                    results_tst[average] = f1_score(tst_y_true, tst_y_pred, average=average)\n",
    "#                 all_results_trn[mode].append(results_trn)\n",
    "#                 all_results_tst[mode].append(results_tst)\n",
    "                print('training: ')\n",
    "                print(results_trn)\n",
    "                print('testing: ')\n",
    "                print(results_tst)\n",
    "        \n",
    "    return tst_y_pred, tst_y_true, tst_logit_y, res_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "def scoring(emb_filename, matfile, mode = None, use_feature = False):\n",
    "    # 0. Files\n",
    "    embeddings_file = emb_filename\n",
    "\n",
    "    if (mode == 'deepwalk-reproduce' or mode == 'semi' or mode == 'icml' or mode == 'dnn'):\n",
    "        # 1. Load Embeddings\n",
    "        embeddings = np.loadtxt(embeddings_file)\n",
    "    elif (mode == 'deepwalk-original'):\n",
    "        ## for original deepwalk\n",
    "        model = KeyedVectors.load_word2vec_format(embeddings_file, binary=False)\n",
    "    elif (mode == 'deepwalk-word2veclib'):\n",
    "        ## for external word2vec lib\n",
    "        model = word2vec.load('/hdd2/graph_embedding/tmp/blogcatalog.embeddings.walks.0.bin')\n",
    "\n",
    "\n",
    "    # 2. Load labels\n",
    "    if (mode == 'icml'):\n",
    "        NAMES = ['x', 'y', 'tx', 'ty', 'graph']\n",
    "        OBJECTS = []\n",
    "        print(DATASET)\n",
    "        for i in range(len(NAMES)):\n",
    "            f = file_path + 'trans.{}.{}'.format(DATASET, NAMES[i])\n",
    "            OBJECTS.append(cPickle.load(open(f)))\n",
    "        x, y, tx, ty, graph = tuple(OBJECTS)\n",
    "        labels_matrix = np.concatenate([y, ty])\n",
    "        labels_count = labels_matrix.shape[1]\n",
    "        mlb = MultiLabelBinarizer(range(labels_count))\n",
    "    else:\n",
    "        mat = sio.loadmat(matfile)\n",
    "        A = mat['network']\n",
    "        graph = sparse2graph(A)\n",
    "        labels_matrix = mat['group']\n",
    "        labels_count = labels_matrix.shape[1]\n",
    "        mlb = MultiLabelBinarizer(range(labels_count))\n",
    "\n",
    "        \n",
    "    if (mode == 'deepwalk-reproduce' or mode == 'semi' or mode == 'icml' or mode == 'dnn'):\n",
    "        # Map nodes to their features (note:  assumes nodes are labeled as integers 1:N)\n",
    "        features_matrix = embeddings\n",
    "    elif (mode == 'deepwalk-original'):\n",
    "        # original code\n",
    "        features_matrix = np.asarray([model[str(node)] for node in range(len(graph))])\n",
    "    elif (mode == 'deepwalk-word2veclib'):\n",
    "        # use other word2vec lib\n",
    "        features_matrix = np.asarray([model[str(node)] for node in range(len(model.vocab)-1)])\n",
    "        rand_list = range(len(model.vocab)-1)\n",
    "        features_matrix = np.asarray([model[str(node)] for node in rand_list])\n",
    "    \n",
    "    if (mode == 'dnn'):\n",
    "        X, y = features_matrix, labels_matrix\n",
    "\n",
    "        with open(data_splited_filename, 'rb') as handle:\n",
    "            unserialized_data = pickle.load(handle)\n",
    "        # trn_idx and tst_idx is the id for the embedding matrix\n",
    "        trn_idx, y_train, tst_idx, y_test = (unserialized_data['trn_idx'], unserialized_data['trn_y'],\n",
    "                                             unserialized_data['tst_idx'], unserialized_data['tst_y'])\n",
    "        \n",
    "#         print(tst_x)\n",
    "#         sys.exit(0)\n",
    "        X_train = X[trn_idx, :]\n",
    "        y_train_ = y[trn_idx]\n",
    "        \n",
    "        y_train = y_train_.todense().tolist()\n",
    "        \n",
    "#         print(trn_idx[0])\n",
    "#         print(labels_matrix[trn_idx[0]].todense().tolist())\n",
    "#         print(y_train[0])\n",
    "        \n",
    "#         sys.exit(0)\n",
    "        \n",
    "        X_test = X[tst_idx, :]\n",
    "        y_test_ = y[tst_idx]\n",
    "        \n",
    "        y_test = y_test_.todense().tolist()\n",
    "        tst_y_pred, tst_y_true, res_logit_y, res_predictions = train_nn_multi_label_classifier(\n",
    "                                                                    mlb, X_train, y_train, X_test, y_test, mode)\n",
    "        return tst_y_pred, tst_y_true, res_logit_y, res_predictions\n",
    "    \n",
    "    if (mode == 'icml'):\n",
    "        if (use_feature):\n",
    "            features_matrix = np.concatenate([x.toarray(), tx.toarray()])\n",
    "            X, y = features_matrix, labels_matrix\n",
    "        else:\n",
    "            X, y = features_matrix, labels_matrix\n",
    "        \n",
    "        trn_x_id = range(0, x.shape[0])\n",
    "        trn_y = y\n",
    "        tst_x_id = range(x.shape[0], x.shape[0] + tx.shape[0])\n",
    "        tst_y = tx\n",
    "            \n",
    "        X_train = X[trn_x_id, :]\n",
    "        y_train = y[trn_x_id]\n",
    "\n",
    "        X_test = X[tst_x_id, :]\n",
    "        y_test = y[tst_x_id]\n",
    "        \n",
    "        clf = TopKRanker(LogisticRegression())\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        all_results_trn, all_results_tst = train_classifier(clf, mlb, X_train, y_train, X_test, y_test, mode)\n",
    "    elif (mode == 'semi'):\n",
    "        # read from trn and tst file\n",
    "        ## Read the data, the trn_x is the position in the embedding matrix\n",
    "        X, y = features_matrix, labels_matrix\n",
    "        \n",
    "\n",
    "        with open(data_splited_filename, 'rb') as handle:\n",
    "            unserialized_data = pickle.load(handle)\n",
    "#         trn_x_id, trn_y, tst_x_id, tst_y = (unserialized_data['trn_x'], unserialized_data['trn_y'],\\\n",
    "#                                             unserialized_data['tst_x'], unserialized_data['tst_y'])\n",
    "        trn_idx, y_train, tst_idx, y_test = (unserialized_data['trn_idx'], unserialized_data['trn_y'],\n",
    "                                             unserialized_data['tst_idx'], unserialized_data['tst_y'])\n",
    "\n",
    "        X_train = X[trn_idx, :]\n",
    "        y_train_ = y[trn_idx]\n",
    "        \n",
    "        y_train = [[] for x in range(y_train_.shape[0])]\n",
    "        \n",
    "        cy =  y_train_.tocoo()\n",
    "        for i, j in zip(cy.row, cy.col):\n",
    "            y_train[i].append(j)\n",
    "\n",
    "        assert sum(len(l) for l in y_train) == y_train_.nnz\n",
    "\n",
    "        X_test = X[tst_idx, :]\n",
    "        y_test_ = y[tst_idx]\n",
    "\n",
    "        y_test = [[] for _ in range(y_test_.shape[0])]\n",
    "\n",
    "        cy =  y_test_.tocoo()\n",
    "        for i, j in zip(cy.row, cy.col):\n",
    "            y_test[i].append(j)\n",
    "\n",
    "        clf = TopKRanker(LogisticRegression())\n",
    "        clf.fit(X_train, y_train_)\n",
    "        \n",
    "        all_results_trn, all_results_tst = train_classifier(clf, mlb, X_train, y_train, X_test, y_test, mode)\n",
    "    else:\n",
    "        # 2. Shuffle, to create train/test groups\n",
    "        print('--------------deepwalk-reproduce-----------:')\n",
    "        shuffles = []\n",
    "        for x in range(1):\n",
    "            shuffles.append(skshuffle(features_matrix, labels_matrix, random_state = 1))\n",
    "\n",
    "        # 3. to score each train/test group\n",
    "        \n",
    "    #     if args.all:\n",
    "    #         training_percents = numpy.asarray(range(1, 10)) * .1\n",
    "    #     else:\n",
    "    #         training_percents = [0.1, 0.5, 0.9]\n",
    "        training_percents = [0.1]\n",
    "        for train_percent in training_percents:\n",
    "            for shuf in shuffles:\n",
    "                \n",
    "                X, y = shuf\n",
    "\n",
    "                training_size = int(train_percent * X.shape[0])\n",
    "\n",
    "                X_train = X[:training_size, :]\n",
    "                y_train_ = y[:training_size]\n",
    "\n",
    "                y_train = [[] for x in range(y_train_.shape[0])]\n",
    "\n",
    "\n",
    "                cy =  y_train_.tocoo()\n",
    "                for i, j in zip(cy.row, cy.col):\n",
    "                    y_train[i].append(j)\n",
    "\n",
    "                assert sum(len(l) for l in y_train) == y_train_.nnz\n",
    "\n",
    "                X_test = X[training_size:, :]\n",
    "                y_test_ = y[training_size:]\n",
    "\n",
    "                y_test = [[] for _ in range(y_test_.shape[0])]\n",
    "\n",
    "                cy =  y_test_.tocoo()\n",
    "                for i, j in zip(cy.row, cy.col):\n",
    "                    y_test[i].append(j)\n",
    "\n",
    "                clf = TopKRanker(LogisticRegression())\n",
    "                clf.fit(X_train, y_train_)\n",
    "                \n",
    "                all_results_trn, all_results_tst = train_classifier(clf, mlb, X_train, y_train, X_test, y_test, mode)\n",
    "\n",
    "    print ('Results, using embeddings of dimensionality', X.shape[1])\n",
    "    print ('-------------------')\n",
    "    for train_percent in sorted(all_results_trn.keys()):\n",
    "        print ('Train percent:', train_percent)\n",
    "    for index, result in enumerate(all_results_trn[train_percent]):\n",
    "        print ('Shuffle #%d:   ' % (index + 1), result)\n",
    "    avg_score = defaultdict(float)\n",
    "    for score_dict in all_results_trn[train_percent]:\n",
    "        for metric, score in iteritems(score_dict):\n",
    "            avg_score[metric] += score\n",
    "    for metric in avg_score:\n",
    "        avg_score[metric] /= len(all_results_trn[train_percent])\n",
    "    print ('Average score:', dict(avg_score))\n",
    "    print ('-------------------')\n",
    "    \n",
    "    for test_percent in sorted(all_results_tst.keys()):\n",
    "        print ('Test percent:', test_percent)\n",
    "    for index, result in enumerate(all_results_tst[test_percent]):\n",
    "        print ('Shuffle #%d:   ' % (index + 1), result)\n",
    "    avg_score = defaultdict(float)\n",
    "    for score_dict in all_results_tst[test_percent]:\n",
    "        for metric, score in iteritems(score_dict):\n",
    "            avg_score[metric] += score\n",
    "    for metric in avg_score:\n",
    "        avg_score[metric] /= len(all_results_tst[test_percent])\n",
    "    print ('Average score:', dict(avg_score))\n",
    "    print ('-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Results, using embeddings of dimensionality', 128)\n",
      "-------------------\n",
      "('Train percent:', 'semi')\n",
      "('Shuffle #1:   ', {'micro': 0.3648366921473245, 'macro': 0.16228035121859019})\n",
      "('Average score:', {'micro': 0.3648366921473245, 'macro': 0.16228035121859019})\n",
      "-------------------\n",
      "('Test percent:', 'semi')\n",
      "('Shuffle #1:   ', {'micro': 0.2968474342256654, 'macro': 0.11376318997761925})\n",
      "('Average score:', {'micro': 0.2968474342256654, 'macro': 0.11376318997761925})\n",
      "-------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-f9808d64290b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata_splited_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/hdd2/graph_embedding/customized/blogcatalog_splited_p10.pickle'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mall_results_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_results_tst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'semi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# tst_y_pred, tst_y_true, res_logit_y, res_predictions = scoring(embedding_filename, matfile, 'dnn', use_feature = False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "DATASET = 'blogcatalog'\n",
    "matfile = '/hdd2/graph_embedding/deepwalk/example_graphs/blogcatalog.mat'\n",
    "embedding_filename = '/hdd2/graph_embedding/customized/results/deepwalk_unsupervised/blog_embeddings_iter840000.txt'\n",
    "embedding_filename_original = '/hdd2/graph_embedding/customized/model_ns5_iter1.output'\n",
    "embedding_filename_other_lib = '/hdd2/graph_embedding/tmp/blogcatalog.embeddings.walks.0.bin'\n",
    "\n",
    "data_splited_filename = '/hdd2/graph_embedding/customized/blogcatalog_splited_p10.pickle'\n",
    "\n",
    "# all_results_trn, all_results_tst = scoring(embedding_filename, matfile, 'semi', use_feature = False)\n",
    "\n",
    "tst_y_pred, tst_y_true, res_logit_y, res_predictions = scoring(embedding_filename, matfile, 'dnn', use_feature = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tst_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.65904423e-02,   3.71109366e-01,   2.48663779e-02,\n",
       "         1.11943260e-01,   3.17886152e-04,   2.21926738e-02,\n",
       "         5.21736443e-02,   2.85875171e-01,   1.83535591e-02,\n",
       "         1.49226580e-02,   3.13785225e-02,   3.16478349e-02,\n",
       "         7.11672306e-02,   8.79293904e-02,   7.02329054e-02,\n",
       "         3.58239710e-02,   6.68537989e-02,   2.25260574e-02,\n",
       "         1.44433752e-01,   2.19396055e-01,   4.57650982e-02,\n",
       "         2.32517011e-02,   3.62364054e-02,   3.63546498e-02,\n",
       "         5.56440651e-02,   6.21089363e-04,   5.83190396e-02,\n",
       "         1.74291618e-02,   1.09781697e-02,   3.73021029e-02,\n",
       "         4.58634347e-02,   2.83731706e-02,   7.82059193e-01,\n",
       "         4.93668094e-02,   4.53660078e-03,   6.76471740e-04,\n",
       "         1.17799696e-02,   2.79791746e-02,   2.69396733e-02], dtype=float32)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res_logit_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-63c7d306492d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres_logit_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'res_logit_y' is not defined"
     ]
    }
   ],
   "source": [
    "res_logit_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_walks_to_disk(G, filebase, num_paths, path_length, alpha=0, rand=random.Random(0), num_workers=cpu_count(),\n",
    "#                         always_rebuild=True):\n",
    "#     global __current_graph\n",
    "#     __current_graph = G\n",
    "#     files_list = [\"{}.{}\".format(filebase, str(x)) for x in list(range(num_paths))]\n",
    "#     expected_size = len(G)\n",
    "#     args_list = []\n",
    "#     files = []\n",
    "\n",
    "#     if num_paths <= num_workers:\n",
    "#         paths_per_worker = [1 for x in range(num_paths)]\n",
    "#     else:\n",
    "#         paths_per_worker = [len(list(filter(lambda z: z!= None, [y for y in x])))\n",
    "#                             for x in graph.grouper(int(num_paths / num_workers)+1, range(1, num_paths+1))]\n",
    "\n",
    "#     with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "#         for size, file_, ppw in zip(executor.map(count_lines, files_list), files_list, paths_per_worker):\n",
    "#             if always_rebuild or size != (ppw*expected_size):\n",
    "#                 args_list.append((ppw, path_length, alpha, random.Random(rand.randint(0, 2**31)), file_))\n",
    "#             else:\n",
    "#                 files.append(file_)\n",
    "\n",
    "#     with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "#         for file_ in executor.map(_write_walks_to_disk, args_list):\n",
    "#             files.append(file_)\n",
    "\n",
    "#     return files\n",
    "\n",
    "\n",
    "\n",
    "def random_walk(graph, num_paths, path_length, rand = random.Random(0)):\n",
    "    vocabulary_size = max(graph.keys()) + 1\n",
    "    i = 0\n",
    "    list_path = []\n",
    "    tot_path = 0\n",
    "    nodes = range(vocabulary_size)\n",
    "    for cnt in range(num_paths):\n",
    "        rand.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            path = [node]\n",
    "            for _ in xrange(path_length-1):\n",
    "                path.append(rand.choice(graph[path[-1]]))\n",
    "            list_path.append(path)\n",
    "    return list_path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hdd2/graph_embedding/planetoid/data/trans.citeseer.x\n",
      "/hdd2/graph_embedding/planetoid/data/trans.citeseer.y\n",
      "/hdd2/graph_embedding/planetoid/data/trans.citeseer.tx\n",
      "/hdd2/graph_embedding/planetoid/data/trans.citeseer.ty\n",
      "/hdd2/graph_embedding/planetoid/data/trans.citeseer.graph\n",
      "Walking...\n"
     ]
    }
   ],
   "source": [
    "## adapt the icml paper to deepwalk\n",
    "DATASET = 'citeseer'\n",
    "number_walks = 50\n",
    "walk_length = 40\n",
    "seed = 1 \n",
    "workers = 1\n",
    "output_filename = '/hdd2/graph_embedding/customized/tmp/%s.embeddings' %(DATASET)\n",
    "def generate_data_icml(file_path, DATASET):\n",
    "    NAMES = ['x', 'y', 'tx', 'ty', 'graph']\n",
    "    OBJECTS = []\n",
    "    for i in range(len(NAMES)):\n",
    "        f = file_path + 'trans.{}.{}'.format(DATASET, NAMES[i])\n",
    "        print(f)\n",
    "        OBJECTS.append(cPickle.load(open(f)))\n",
    "    x, y, tx, ty, graph = tuple(OBJECTS)\n",
    "    \n",
    "    num_walks = len(graph) * number_walks\n",
    "    \n",
    "    print(\"Walking...\")\n",
    "    walk = random_walk(graph, number_walks, walk_length)\n",
    "\n",
    "    return walk\n",
    "file_path = '/hdd2/graph_embedding/planetoid/data/'\n",
    "walks_filebase = output_filename + \".walks\"\n",
    "walk = generate_data_icml(file_path, DATASET)\n",
    "np.savetxt(walks_filebase, walk, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hdd2/graph_embedding/planetoid/data/trans.citeseer.x\n",
      "/hdd2/graph_embedding/planetoid/data/trans.citeseer.y\n",
      "/hdd2/graph_embedding/planetoid/data/trans.citeseer.tx\n",
      "/hdd2/graph_embedding/planetoid/data/trans.citeseer.ty\n",
      "/hdd2/graph_embedding/planetoid/data/trans.citeseer.graph\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'citeseer'\n",
    "NAMES = ['x', 'y', 'tx', 'ty', 'graph']\n",
    "OBJECTS = []\n",
    "for i in range(len(NAMES)):\n",
    "    f = file_path + 'trans.{}.{}'.format(DATASET, NAMES[i])\n",
    "    print(f)\n",
    "    OBJECTS.append(cPickle.load(open(f)))\n",
    "x, y, tx, ty, graph = tuple(OBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3703)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "fx = x.toarray()\n",
    "y_true = [np.nonzero(e)[0][0] for e in y]\n",
    "ftx = tx.toarray()\n",
    "ty_true = [np.nonzero(e)[0][0] for e in ty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_filename = '/hdd2/graph_embedding/customized/results/exp_citeseer_semi/citeseer_embeddings_iter23.txt'\n",
    "embeddings = np.loadtxt(embedding_filename)\n",
    "emb_x = embeddings[:x.shape[0] , :]\n",
    "emb_tx = embeddings[x.shape[0]:x.shape[0] + ftx.shape[0], :]\n",
    "\n",
    "# xx = np.concatenate([fx, emb_x], axis = 1)\n",
    "# txx = np.concatenate([ftx, emb_tx], axis = 1)\n",
    "# xx = fx\n",
    "# txx = ftx\n",
    "\n",
    "xx = emb_x\n",
    "txx = emb_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.49200000\n",
      "macro f1: 0.47034972\n",
      "micro f1: 0.49200000\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(xx, y_true)\n",
    "ty_pred = logreg.predict(txx)\n",
    "print('acc: %.8f' %(accuracy_score(ty_true, ty_pred)))\n",
    "print('macro f1: %.8f' %f1_score(ty_true, ty_pred, average='macro'))\n",
    "print('micro f1: %.8f' %f1_score(ty_true, ty_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 128)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3831)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x3703 sparse matrix of type '<type 'numpy.float32'>'\n",
       "\twith 58 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
